{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNC/PihRbeov0ZcQ+6dABi2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "julia",
      "display_name": "Julia"
    },
    "language_info": {
      "name": "julia"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegoax/ALNAE-2025/blob/main/notebooks/clase8_ALNAE_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase 8 (Miércoles 9 de abril, 2025)\n",
        "---"
      ],
      "metadata": {
        "id": "X4LxHqF6tmVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>\n",
        "<b>Breve reseña sobre los números complejos</b>\n",
        "</summary>\n",
        "\n",
        "### Números complejos (resumen)\n",
        "Un número complejo se escribe de la forma $z = a + bi$, con $i^2 = -1$ la unidad imaginaria.\n",
        "- **Parte real:** $\\operatorname{Re}(z) = a$  \n",
        "- **Parte imaginaria:** $\\operatorname{Im}(z) = b$\n",
        "---\n",
        "### Geometría en el plano complejo\n",
        "\n",
        "- Se representa $z = a + bi$ como el punto $(a, b)$ en el plano.\n",
        "- El **módulo** es la distancia al origen: $|z| = \\sqrt{a^2 + b^2}$\n",
        "- El **argumento** $\\theta = \\arg(z)$ es el ángulo entre el eje real y el vector $z$ (medido desde el origen).\n",
        "- La **exponencial compleja** viene dada por\n",
        "$$\n",
        "e^{i\\theta}=\\cos \\theta + i \\sin \\theta,\n",
        "$$\n",
        "de donde surge la famosa fórmula:\n",
        "$$\n",
        "e^{i\\pi}=-1.\n",
        "$$\n",
        "Obsevar que $e^{i\\theta}$ parametriza todos los puntos de $S^1=\\{z\\in\\mathbb{C}:\\, |z|=1\\}$.\n",
        "- La **forma polar**:  \n",
        "  $$z = r(\\cos \\theta + i \\sin \\theta) = re^{i\\theta}, \\quad \\text{con } r = |z|, \\ \\theta = \\arg(z)$$\n",
        "\n",
        "---\n",
        "\n",
        "### Propiedades básicas\n",
        "\n",
        "- **Suma/resta:**  (somo si fueran reales, o como sumar vectores del plano)\n",
        "  $$(a + bi) \\pm (c + di) = (a \\pm c) + (b \\pm d)i$$\n",
        "\n",
        "- **Multiplicación:**  (como si fueran reales, con el agregado $i^2=-1$\n",
        "  $$(a + bi)(c + di) = (ac - bd) + (ad + bc)i$$\n",
        "(es importante destacar que la propiedad de multiplicar vectores, y me devuelva un vector, no es fácilmente generalizable a otras dimensiones. Esto hace que los números complejos un espacio tan interesante.)\n",
        "- **Conjugado:**  \n",
        "  $$\\overline{z} = a - bi$$\n",
        "\n",
        "- **Módulo:**  \n",
        "  $$|z| = \\sqrt{a^2 + b^2}$$\n",
        "\n",
        "- **División:**  \n",
        "  $$\\frac{z_1}{z_2} = \\frac{z_1 \\, \\overline{z_2}}{|z_2|^2}, \\quad \\text{si } z_2 \\ne 0$$\n",
        "\n",
        "- **Teorema de De Moivre:**  \n",
        "  $$(re^{i\\theta})^n = r^n e^{in\\theta}$$\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretación geométrica\n",
        "\n",
        "- **Suma:** suma de vectores en el plano\n",
        "- **Multiplicación:** escala el módulo y **rota** el ángulo\n",
        "- **Conjugado:** reflejo respecto al eje real\n",
        "- **División:** divide módulos y **resta** ángulos\n",
        "</details>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "eFWlpIkO3LG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Valores propios de matrices ortogonales\n",
        "\n",
        "Una matriz $Q \\in \\mathbb{R}^{n \\times n}$ es **ortogonal** si:\n",
        "$$\n",
        "Q^\\top Q = QQ^\\top = I\n",
        "$$\n",
        "\n",
        "**¿Puede una matriz ortogonal no tener vectores propios reales?**\n",
        "\n",
        "**Sí.**  \n",
        "Una matriz ortogonal puede no tener ningún vector propio real.\n",
        "\n",
        "---\n",
        "\n",
        "*Ejemplo*: rotación de $\\pi/2$\n",
        "\n",
        "$$\n",
        "Q = \\begin{bmatrix}\n",
        "0 & -1 \\\\\n",
        "1 & 0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "- cualquier vector lo rota $\\pi/2$ por lo tanto no pueden ser propios\n",
        "- En particular, $\\chi_Q(z)=z^2+1$\n",
        "- Sin embargo $\\chi_Q$ tiene raíces complejas, a saber, $\\lambda = \\pm i$\n",
        "- No existen vectores propios reales asociados\n",
        "- Los vectores propios están en $\\mathbb{C}^2$, no en $\\mathbb{R}^2$.\n",
        "- Veamos que que hay vectores propios complejos:\n",
        "- **Ejercicio:** Probar que $x_1=[1,-i]$ y $x_2=[1,i]$ son vectores propios con valores propios $i$ e $-i$.\n",
        "- **Ejercicio:** Observar que $x_1$ y $x_2$ son ortogonales (con el producto interno en $\\mathbb{C}^2$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qBfhZEPCBQuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### Propiedades del espectro de matrices aleatoria\n",
        "\n",
        "1. **Módulo uno:**  \n",
        "   Si $\\lambda$ es un valor propio de $Q$, entonces $|\\lambda| = 1$. (Dado que preserva normas.)\n",
        "\n",
        "<details><summary>Prueba</summary>\n",
        "\n",
        "Sea $Qx = \\lambda x$ con $x \\ne 0$. Entonces:\n",
        "$$\n",
        "\\|x\\|^2 = \\|Qx\\|^2 = \\|\\lambda x\\|^2 = |\\lambda|^2 \\|x\\|^2 \\Rightarrow |\\lambda|^2 = 1 \\Rightarrow |\\lambda| = 1\n",
        "$$\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "2. **Valores propios reales posibles:**  \n",
        "   Solo pueden ser $\\lambda = \\pm 1$.\n",
        "\n",
        "<details><summary>Prueba</summary>\n",
        "\n",
        "Si $\\lambda$ es real y $|\\lambda| = 1$, entonces $\\lambda = \\pm 1$.\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "3. **Valores propios complejos vienen en pares conjugados:**\n",
        "\n",
        "<details><summary>Prueba</summary>\n",
        "\n",
        "Esto resulta de que polinomios con coeficientes reales, que tengan una raíz compleja, también tiene a su conjugada.\n",
        "\n",
        "Si $Q$ es ortogonal y $\\lambda$ es complejo con vector propio $v$, entonces:\n",
        "$$\n",
        "Q\\overline{v} = \\overline{Qv} = \\overline{\\lambda v} = \\overline{\\lambda} \\, \\overline{v}\n",
        "$$\n",
        "Por lo tanto, $\\overline{\\lambda}$ también es valor propio con vector propio $\\overline{v}$.\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "4. **Determinante $\\det(Q) = \\pm 1$**\n",
        "\n",
        "<details><summary>Prueba</summary>\n",
        "\n",
        "La propiedad $Q^\\top Q = I$ implica que $\\det(Q)^2 = \\det(Q^\\top Q) = \\det(I) = 1$  \n",
        "Entonces $|\\det(Q)| = 1 \\Rightarrow \\det(Q) = \\pm 1$\n",
        "\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "### Ejemplo 1: matriz de rotación\n",
        "\n",
        "$$\n",
        "Q = \\begin{bmatrix}\n",
        "\\cos \\theta & -\\sin \\theta \\\\\n",
        "\\sin \\theta & \\cos \\theta\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "- Si $\\theta \\notin \\{0, \\pi\\}$, los valores propios son complejos:  \n",
        "  $$\\lambda = e^{\\pm i\\theta}$$\n",
        "\n",
        "- Si $\\theta = 0$: $\\lambda = 1$ (identidad)  \n",
        "- Si $\\theta = \\pi$: $\\lambda = -1$ (rotación de 180°)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "15uyDNjv-V2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Valores propios de matrices similares\n",
        "\n",
        "Dos matrices $A$ y $B$ son **similares** si existe una matriz invertible $P$ tal que:\n",
        "$$\n",
        "B = P A P^{-1}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### Propiedad clave\n",
        "\n",
        "**Las matrices similares tienen los mismos valores propios.**\n",
        "**Quiénes son los vectores propios?**\n",
        "\n",
        "<details><summary>Idea de la prueba 1 </summary>\n",
        "\n",
        "Sea $\\lambda$ valor propio de $A$, es decir:\n",
        "$$\n",
        "A v = \\lambda v \\quad \\text{con } v \\ne 0\n",
        "$$\n",
        "\n",
        "Definimos $w = Pv$. Entonces:\n",
        "$$\n",
        "B w = P A P^{-1} w = P A v = P(\\lambda v) = \\lambda Pv = \\lambda w\n",
        "$$\n",
        "\n",
        "Por tanto, $\\lambda$ también es valor propio de $B$.\n",
        "\n",
        "Es decir, si $v_i$ son los vectores propios de $A$, entonces $Pv_i$ son los de $PAP^{-1}$.\n",
        "</details>\n",
        "\n",
        "<details><summary>Idea de la prueba 2: mismo polinomio característico </summary>\n",
        "Observar que el polinomio caracterísitco queda invariante:\n",
        "$$\n",
        "\\det( P A P^{-1}-z\\textrm{Id})=\\det( P A P^{-1}-zPP^{-1})\\det(P(A-z\\textrm{Id})P^{-1})\\\\\n",
        "=\\det(P)\\det(A-z\\textrm{Id})\\det(P^{-1})=\\det(A-z\\textrm{Id})\n",
        "$$\n",
        "</details>\n",
        "\n",
        "---\n",
        "\n",
        "### Consecuencias\n",
        "\n",
        "- Misma **traza** y **determinante**\n",
        "<details>\n",
        "<summary> Por qué? </summary>\n",
        "Por la traza y determinantes son coeficientes de polinomio caracterísiticos.\n",
        "</details>\n",
        "- **Vectores propios** pueden ser distintos"
      ],
      "metadata": {
        "id": "99FjW6Sa-z0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teorema Espectral\n",
        "\n",
        "Sabemos que si $S$ es una matriz $m\\times m$ simétrica entonces se diagonaliza en una base ortonormal de vectores propios. Con nuestras notaciones tenemos que\n",
        "\n",
        "**\"Si $S$ es simétrica, entonces existe una matriz diagonal $D$ y una matriz ortogonal $Q$ tal que $S=QDQ^T$\".**\n",
        "\n",
        "Veamos dos pruebas de este resultado pero antes una breve discusión sobre temas de cálculo diferencial e integral en varias variables, a saber, **derivadas direccionales**."
      ],
      "metadata": {
        "id": "u4U9LxZQZmeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Derivada Direccional\n",
        "\n",
        "Sea $f:U\\subset\\mathbb{R}^n\\to \\mathbb R$, una función diferenciable definida en un conjunto abierto. Entonces dado un punto $a\\in U$, y un vector genérico $v\\in\\mathbb{R}^n$ podemos definir la **derivada direcciónal de $f$ en $a$ en la dirección de $v$** como:\n",
        "$$\n",
        "\\partial_v f(a):=\\lim_{t\\to 0}\\frac{f(a+tv)-f(a)}{t}.\n",
        "$$\n",
        "Básicamente, $\\partial_v f(a)$ mide la variacion de $f$ a lo largo de la recta $t\\mapsto a+tv$ para $t$ chico.\n",
        "\n",
        "###Comentarios\n",
        "\n",
        "1. Es fácil ver que si tomamos la curva (rectilínea)\n",
        "$$\n",
        "\\alpha(t)=a+tv,\\qquad t\\in (-\\delta,\\delta)\n",
        "$$\n",
        "(definida en un entorno del punto $a$) entonces\n",
        "\\begin{align*}\n",
        "\\frac{d}{dt}\\big|_{t=0}f(\\alpha(t))&:=(f\\circ \\alpha)'(0):= \\lim_{t\\to 0}\\frac{(f\\circ \\alpha)(t)-(f\\circ\\alpha)(0)}{t}\\\\\n",
        "&=\\lim_{t\\to0}\\frac{f(\\alpha(t))-f(\\alpha(0))}{t}= \\lim_{t\\to 0}\\frac{f(a+tv)-f(a)}{t}= \\partial_v f(a).\n",
        "\\end{align*}\n",
        "Con esto concluimos que la derivada direccional $\\partial_v f(a)$ no es otra cosa que derivar la función de una variable  $t\\mapsto f(a+tv)$ (es decir, derivar la restricción de $f$ a la recta).\n",
        "2. Del comentario 1. y  la regla de la cadena tenemos que\n",
        "$$\n",
        "(f\\circ \\alpha)'(0)=Df(\\alpha(0))\\cdot\\alpha'(0)=Df(a)v  \\quad(*)\n",
        "$$\n",
        "siendo $Df(a)$ la derivada de $f$ en $a$, o matriz jacobiana, (y donde usamos que $\\alpha(0)=a$ y $\\alpha'(0)=v$.\n",
        "De esto resulta que\n",
        "$$\\partial_v f(a)= \\nabla f(a)^Tv.\n",
        "$$\n",
        "3. Una observación importante que se deduce de (*) es que en realidad nuestra curva $\\alpha(t)$ puede ser cualquier curva diferenciable tal que $\\alpha(0)=a$ y $\\alpha'(0)=v$. Es decir, que para calcular $\\partial_vf(a)$, basta calcular\n",
        "$\\frac{d}{dt}\\big|_{t=0}f(\\beta(t))$ para cualquier curva $\\beta$ tal que $\\beta(0)=a$ y $\\beta'(0)=v$."
      ],
      "metadata": {
        "id": "T66zSMnxZ2mX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prueba via forma cuadrática\n",
        "\n",
        "Sea $\\mathbb{S}^{m-1}$ la esfera unitaria en $\\mathbb{R}^m$.\n",
        "\n",
        "Si consideramos la forma cuadrática $f:\\mathbb{S}^{m-1}\\to \\mathbb{R}$ dada por\n",
        "$$f(x)=x^TSx,\\qquad x\\in \\mathbb{S}^{m-1}.$$\n",
        "\n",
        "Observar que $f$ es continua y por lo tanto tiene máximo y mínimo en la esfera (por ser esta compacta).\n",
        "\n",
        "Miremos el máximo (análogo para el mínimo). Observar que\n",
        "$$\n",
        "x_1=\\textrm{argmax}_{x\\in\\mathbb{S}^{m-1}} f(x),\n",
        "$$\n",
        "tiene que ser un punto crítico de $f$. Por lo tanto, la derivada (definida sobre la esfera tiene que ser cero).\n",
        "\n",
        "Calculemos la derivada de $f$ sobre un punto $x\\in\\mathbb{S}^{m-1}$. Para todo $\\dot x$, se tiene\n",
        "$$\n",
        "Df(x)\\dot x=\\dot x^TSx+x^TS\\dot x= \\dot x^TSx+\\underbrace{\\dot x^TS^T x}_{\\mbox{trasponiendo}}= 2\\dot x^TSx.\n",
        "$$\n",
        "(Hicimos de manera poco formal, pero funciona.)\n",
        "\n",
        "---\n",
        "\n",
        "**Ejercicio:** Para convecerse de este cálculo, pueden tomar la curva\n",
        "$$\n",
        "\\alpha(t)=\\cos(t)x+\\sin(t)\\dot x,\\qquad t\\in\\mathbb{R},\n",
        "$$\n",
        "y calcular a mano la derivada siguiente (aplicando distributiva y fuerza bruta, y algo de chispa para los cálculos por que mucha cosa se va)\n",
        "$$\n",
        "\\frac{d}{dt}\\big|_{t=0}f(\\alpha(t))= \\frac{d}{dt}\\big|_{t=0}\n",
        "\\alpha(t)^TS\\alpha(t).\n",
        "$$\n",
        "Observar que la cuenta anterior no es otra cosa que $Df(x)\\dot x$.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Por lo tanto $x$ es punto crítico de $f$ en $\\mathbb{S}^{m-1}$ si\n",
        "$$\n",
        "\\dot x^TSx=0\\qquad\\mbox{para todo vector }\\dot x\\in x^\\perp.\n",
        "$$\n",
        "Eso ocurre sí y solo sí $Sx$ es paralelo a $x$, i.e. si existe $\\lambda\\in\\mathbb R$ tal que\n",
        "$$\n",
        "Sx=\\lambda x,\n",
        "$$\n",
        "i.e. los puntos críticos de $f$ son vectores propios de $S$.\n",
        "\n",
        "Luego por ser $x_1$ donde se alcanza el máximo de $f$, se tiene que existe $\\lambda_1$ tal que $Sx_1=\\lambda_1 x_1$.\n",
        "\n",
        "**Ejercicio:** $S$ deja invariante $x_1^\\perp$, i.e. $ x_1^TSx=0$ para todo $x\\perp x_1$.\n",
        "\n",
        "La afirmación anterior nos permite realizar inducción completa en el tamaño de la matriz. Esto resulta de que $S$ restringido a $x_1$ es una transformación lineal simétrica.\n",
        "La version matricial sería, si $Q$ es una matriz ortogonal con primer vector $x_1$, entonces $Q^TSQ$ es una matriz de la forma\n",
        "$$Q^TSQ=\n",
        "\\begin{pmatrix}\n",
        "\\lambda_1 & 0\\\\\n",
        "0 & \\hat S\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "donde $\\hat S$ es una matriz simétrica. (Y observar que $Q^TSQ$ tiene el mismo espectro que $S$ y por lo tanto $\\hat S$ tiene el resto de los valores propios. Luego hacemos todo lo anterior para la matriz $\\hat S$ de tamaño $(m-1)\\times (m-1)$.\n",
        "\n",
        "**Comentario:** Una versión alternativa de prueba es usar los multiplicadores de Lagrange. Dado que queremos encontrar el máximo de $f$ en la esfera, basta considerar el problema de optimización con restricciones:\n",
        "$$\n",
        "\\max_{\\|x\\|^2=1}f(x)\n",
        "$$\n",
        "Considerando la función $g:\\mathbb{R}^n\\to\\mathbb R$, con $g(x)=\\|x\\|^2-1$, tenemos que el optimo se encuentra en las soluciones de\n",
        "$$\n",
        "\\nabla f(x)=\\lambda \\nabla g(x), \\quad\\mbox{con}\\quad \\|x\\|^2=1.\n",
        "$$\n",
        "De la prueba anterior se tiene $\\nabla f(x)=2Sx$, y es fácil ver que $\\nabla g(x)=2x$, por lo que los óptimos están en las soluciones de\n",
        "$$\n",
        "2Sx=2\\lambda x, \\quad \\|x\\|^2=1.\n",
        "$$\n",
        "Es decir, el máximo se encuentra en los vectores propios de $S$. La prueba como la anterior.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XDS01gaRfyCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ortogonalidad de espacios propios distintos\n",
        "En la prueba que vimos, se observa que los vectores propios de matrices simétricas son ortogonales. Veamos otra evidencia de esto hecho.\n",
        "\n",
        "Supongamos que $\\lambda$ es valor propio de $S$ simétrica. (Por ejemplo el $\\lambda_1$ de la prueba.)\n",
        "\n",
        "El núcleo de $(S-\\lambda \\textrm{Id})$  es exactamente el espacio propio asociado al valor propio $\\lambda$.\n",
        "\n",
        "Como el núcleo de $(S-\\lambda \\textrm{Id})$ es ortogonal a la imagen de $(S-\\lambda\\textrm{Id})^T$, y $S$ es simétrica, podemo concluir el siguiente hecho:\n",
        "$$\n",
        "\\mbox{espacio propio asociado a }\\lambda \\perp \\textrm{Im} (S-\\lambda\\textrm{Id})\n",
        "$$\n",
        "\n",
        "**Afirmación:** $\\textrm{Im} (S-\\lambda\\textrm{Id})$ contiene al resto de los vectores propios:\n",
        "\n",
        "Si existe $y\\in\\mathbb{R} ^m$ otro vector propio:\n",
        "$$\n",
        "Sy=\\mu y, \\quad \\mu\\in\\mathbb R, (\\mu\\neq \\lambda).\n",
        "$$\n",
        "Entonces tenemos que $(S-\\lambda\\textrm{Id})y=(\\mu-\\lambda)y$ y por lo tanto $y$ está en la imagen de $S-\\lambda \\textrm{Id}$\n",
        "\n",
        "Este última afirmación es independiente de si $S$ es simétrica o no.\n"
      ],
      "metadata": {
        "id": "uJVfJyqobWAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary> <b>Teorema espectral para matrices normales*</b> </summary>\n",
        "\n",
        "Existe una versión más general de este teorema que es para matrices normales: $A$ es normal si $AA^*=A^*A$, siendo $A^*$ la conjugada traspuesta. El teorema espectral en este caso dice que existe un matriz unitaria $U$ (i.e. $U^*U=\\textrm{Id}$) tal que $A=UDU^*$ con $D$ diagonal con entradas complejas.\n",
        "\n",
        "Esto aplica por ejemplo a matrices ortogonales donde $Q^*=Q^T$, y  por lo tanto\n",
        "$$Q^*Q=Q^TQ=\\textrm{Id}=QQ^T=QQ^*$$.\n",
        "\n",
        "Por esa razón sabemos que se diagonaliza sobre una base de vectores complejos ortogonales (con producto interno complejo).\n",
        "</details>"
      ],
      "metadata": {
        "id": "DTOEj5Pxd9Mq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wPdBYlOSRXbC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}